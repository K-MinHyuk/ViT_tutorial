{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating all Modules\n",
    "\n",
    "<center>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"./img/vit.gif\" alt=\"Transformer Encoder\" width=\"50%\" height=\"50%\">\n",
    "</figure>\n",
    "<figcaption style=\"text-align:center; font-size:15px; color:#808080; margin-top:40px\">\n",
    "    \"Image from: https://github.com/lucidrains/vit-pytorch\"\n",
    "  </figcaption>\n",
    "\n",
    "</center>\n",
    "\n",
    "마무리 하는 김에, 좋은 이미지가 있어서 포함 시켰습니다. \n",
    "\n",
    "이번 장에서는, 이전 장의 내용과 더불어 MLP ( Multi-Layer-Perceptron ) 를 추가하여 ViT 를 완성하도록 하겠습니다. \n",
    "\n",
    "이미지상에서 특이한 부분은 MLP-Head 가 상당히 왼쪽에 치우쳐져 있다는 점 입니다. \n",
    "\n",
    "이는, Transformer Encoder 의 출력값 중에 0번째 patch 에 해당하는,\\\n",
    "즉, 순서 상으로 label patch 에 해당하는 출력값을 사용한다는 것입니다.\n",
    "\n",
    "논문에서 설명하는 방법으로는 label patch 위치의 출력만 사용하지만, \\\n",
    "많은 구현 내용을 참고한 결과, 전체 patch 의 mean 으로 사용하는 경우가 많이 있었습니다.\n",
    "\n",
    "이 부분을 그대로 녹여서 ViT 를 구현해 보도록 하죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from torchsummary import summary\n",
    "from collections import OrderedDict\n",
    "from typing import Optional\n",
    "\n",
    "from utils.vit_utils import Image_Embedding # 이전 장의 image embedding\n",
    "from utils.vit_utils import TransformerEncoder # 이전 장의 TransformerEncoder\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([6, 3, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "ims = torch.Tensor(np.load('./resources/test_images.npy', allow_pickle=False))\n",
    "ims = rearrange(ims, 'b h w c -> b c h w')\n",
    "print(type(ims), ims.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Embedding shape: torch.Size([6, 37, 768]) \n",
      "Encoder output shape: torch.Size([6, 37, 768])\n"
     ]
    }
   ],
   "source": [
    "image_embedding = Image_Embedding(image_size = ims.shape[1:], patch_size=16).to(device)\n",
    "embedded_tensor = image_embedding(ims.to(device))\n",
    "\n",
    "transformerencoder = TransformerEncoder(embedding_size = 768, num_heads = 8).to(device)\n",
    "encoder_output = transformerencoder(embedded_tensor)\n",
    "print('Image Embedding shape:', embedded_tensor.shape, '\\nEncoder output shape:', encoder_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "##  MLP-Head \n",
    "\n",
    "위에서는 이전 장의 내용반복 이므로, 넘어가도록 하죠.\n",
    "\n",
    "앞에서 언급했듯, Tensor 를 Reduce 하는 방식에 집중해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Head(nn.Module):\n",
    "    def __init__(self, embedding_size: int = 768, n_classes: int = 1000, reduce_type: Optional[str] = None):\n",
    "        super(MLP_Head, self).__init__()\n",
    "        self.reduce_type = reduce_type\n",
    "        self.r_layer = self.reducelayer()\n",
    "        self.layers = nn.Sequential(\n",
    "                nn.LayerNorm(embedding_size), \n",
    "                nn.Linear(embedding_size, n_classes)\n",
    "                )\n",
    "        \n",
    "    def reducelayer(self):\n",
    "        if self.reduce_type == None:\n",
    "            return lambda x: x[:, 0]\n",
    "        elif self.reduce_type == 'mean':\n",
    "            return Reduce('b p e -> b e', reduction='mean')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.r_layer(x)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적인 `layer` 는 `layernorm` 과 `linear layer` 로 구성이 되어 있습니다. \n",
    "\n",
    "`linear layer` 는 embedding size 를 입력 받아, classification 하는 class 의 개수로 mapping 하게 되어 있습니다. \n",
    "\n",
    "`reducelayer()` 함수는 `redyce_type` 이라는 hyper-parameter 에 의해 patch 의 mean 값을 사용할 수 있고, \n",
    "\n",
    "논문의 구현 내용처럼 patch 의 가장 첫 번째값 만을 사용할 수도 있습니다.\n",
    "\n",
    "einops 의 사용은 이제 익숙하실 것이라 믿습니다.\n",
    "\n",
    "이제 MLP-Head 의 입$\\cdot{}$출력 차원을 확인해 보시죠!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: torch.Size([6, 37, 768]) \n",
      "Result shape: torch.Size([6, 1000])\n"
     ]
    }
   ],
   "source": [
    "mlp_head = MLP_Head().to(device)\n",
    "result = mlp_head(encoder_output)\n",
    "print('Encoder output shape:', encoder_output.shape, '\\nResult shape:', result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "## ViT \n",
    "\n",
    "이제 앞에서 다룬 모든 module 들을 사용하여 ViT 를 구현해 보죠!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self,     \n",
    "                img_size: list[int, int, int],\n",
    "                patch_size: int = 16,\n",
    "                embedding_size: int = 768,\n",
    "                depth: int = 12,\n",
    "                n_classes: int = 1000,\n",
    "                reduce_type: Optional[str] = None,\n",
    "                **kwargs):\n",
    "        super(ViT, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            Image_Embedding(img_size, patch_size, embedding_size),\n",
    "            TransformerEncoder(depth, **kwargs),\n",
    "            MLP_Head(n_classes=n_classes, reduce_type=reduce_type),\n",
    "            torch.nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         LayerNorm-1            [-1, 3, 96, 96]          55,296\n",
      "            Conv2d-2            [-1, 768, 6, 6]         590,592\n",
      "         LayerNorm-3            [-1, 768, 6, 6]          55,296\n",
      "   Image_Embedding-4              [-1, 37, 768]               0\n",
      "         LayerNorm-5              [-1, 37, 768]           1,536\n",
      "            Linear-6              [-1, 37, 768]         590,592\n",
      "            Linear-7              [-1, 37, 768]         590,592\n",
      "            Linear-8              [-1, 37, 768]         590,592\n",
      "            Linear-9              [-1, 37, 768]         590,592\n",
      "Multi_Head_Attention-10              [-1, 37, 768]               0\n",
      "          Dropout-11              [-1, 37, 768]               0\n",
      "ResidualConnection-12              [-1, 37, 768]               0\n",
      "        LayerNorm-13              [-1, 37, 768]           1,536\n",
      "           Linear-14             [-1, 37, 3072]       2,362,368\n",
      "             GELU-15             [-1, 37, 3072]               0\n",
      "          Dropout-16             [-1, 37, 3072]               0\n",
      "           Linear-17              [-1, 37, 768]       2,360,064\n",
      "      FeedForward-18              [-1, 37, 768]               0\n",
      "          Dropout-19              [-1, 37, 768]               0\n",
      "ResidualConnection-20              [-1, 37, 768]               0\n",
      "Transformer_Block-21              [-1, 37, 768]               0\n",
      "        LayerNorm-22              [-1, 37, 768]           1,536\n",
      "           Linear-23              [-1, 37, 768]         590,592\n",
      "           Linear-24              [-1, 37, 768]         590,592\n",
      "           Linear-25              [-1, 37, 768]         590,592\n",
      "           Linear-26              [-1, 37, 768]         590,592\n",
      "Multi_Head_Attention-27              [-1, 37, 768]               0\n",
      "          Dropout-28              [-1, 37, 768]               0\n",
      "ResidualConnection-29              [-1, 37, 768]               0\n",
      "        LayerNorm-30              [-1, 37, 768]           1,536\n",
      "           Linear-31             [-1, 37, 3072]       2,362,368\n",
      "             GELU-32             [-1, 37, 3072]               0\n",
      "          Dropout-33             [-1, 37, 3072]               0\n",
      "           Linear-34              [-1, 37, 768]       2,360,064\n",
      "      FeedForward-35              [-1, 37, 768]               0\n",
      "          Dropout-36              [-1, 37, 768]               0\n",
      "ResidualConnection-37              [-1, 37, 768]               0\n",
      "Transformer_Block-38              [-1, 37, 768]               0\n",
      "        LayerNorm-39              [-1, 37, 768]           1,536\n",
      "           Linear-40              [-1, 37, 768]         590,592\n",
      "           Linear-41              [-1, 37, 768]         590,592\n",
      "           Linear-42              [-1, 37, 768]         590,592\n",
      "           Linear-43              [-1, 37, 768]         590,592\n",
      "Multi_Head_Attention-44              [-1, 37, 768]               0\n",
      "          Dropout-45              [-1, 37, 768]               0\n",
      "ResidualConnection-46              [-1, 37, 768]               0\n",
      "        LayerNorm-47              [-1, 37, 768]           1,536\n",
      "           Linear-48             [-1, 37, 3072]       2,362,368\n",
      "             GELU-49             [-1, 37, 3072]               0\n",
      "          Dropout-50             [-1, 37, 3072]               0\n",
      "           Linear-51              [-1, 37, 768]       2,360,064\n",
      "      FeedForward-52              [-1, 37, 768]               0\n",
      "          Dropout-53              [-1, 37, 768]               0\n",
      "ResidualConnection-54              [-1, 37, 768]               0\n",
      "Transformer_Block-55              [-1, 37, 768]               0\n",
      "        LayerNorm-56              [-1, 37, 768]           1,536\n",
      "           Linear-57              [-1, 37, 768]         590,592\n",
      "           Linear-58              [-1, 37, 768]         590,592\n",
      "           Linear-59              [-1, 37, 768]         590,592\n",
      "           Linear-60              [-1, 37, 768]         590,592\n",
      "Multi_Head_Attention-61              [-1, 37, 768]               0\n",
      "          Dropout-62              [-1, 37, 768]               0\n",
      "ResidualConnection-63              [-1, 37, 768]               0\n",
      "        LayerNorm-64              [-1, 37, 768]           1,536\n",
      "           Linear-65             [-1, 37, 3072]       2,362,368\n",
      "             GELU-66             [-1, 37, 3072]               0\n",
      "          Dropout-67             [-1, 37, 3072]               0\n",
      "           Linear-68              [-1, 37, 768]       2,360,064\n",
      "      FeedForward-69              [-1, 37, 768]               0\n",
      "          Dropout-70              [-1, 37, 768]               0\n",
      "ResidualConnection-71              [-1, 37, 768]               0\n",
      "Transformer_Block-72              [-1, 37, 768]               0\n",
      "        LayerNorm-73              [-1, 37, 768]           1,536\n",
      "           Linear-74              [-1, 37, 768]         590,592\n",
      "           Linear-75              [-1, 37, 768]         590,592\n",
      "           Linear-76              [-1, 37, 768]         590,592\n",
      "           Linear-77              [-1, 37, 768]         590,592\n",
      "Multi_Head_Attention-78              [-1, 37, 768]               0\n",
      "          Dropout-79              [-1, 37, 768]               0\n",
      "ResidualConnection-80              [-1, 37, 768]               0\n",
      "        LayerNorm-81              [-1, 37, 768]           1,536\n",
      "           Linear-82             [-1, 37, 3072]       2,362,368\n",
      "             GELU-83             [-1, 37, 3072]               0\n",
      "          Dropout-84             [-1, 37, 3072]               0\n",
      "           Linear-85              [-1, 37, 768]       2,360,064\n",
      "      FeedForward-86              [-1, 37, 768]               0\n",
      "          Dropout-87              [-1, 37, 768]               0\n",
      "ResidualConnection-88              [-1, 37, 768]               0\n",
      "Transformer_Block-89              [-1, 37, 768]               0\n",
      "        LayerNorm-90              [-1, 37, 768]           1,536\n",
      "           Linear-91              [-1, 37, 768]         590,592\n",
      "           Linear-92              [-1, 37, 768]         590,592\n",
      "           Linear-93              [-1, 37, 768]         590,592\n",
      "           Linear-94              [-1, 37, 768]         590,592\n",
      "Multi_Head_Attention-95              [-1, 37, 768]               0\n",
      "          Dropout-96              [-1, 37, 768]               0\n",
      "ResidualConnection-97              [-1, 37, 768]               0\n",
      "        LayerNorm-98              [-1, 37, 768]           1,536\n",
      "           Linear-99             [-1, 37, 3072]       2,362,368\n",
      "            GELU-100             [-1, 37, 3072]               0\n",
      "         Dropout-101             [-1, 37, 3072]               0\n",
      "          Linear-102              [-1, 37, 768]       2,360,064\n",
      "     FeedForward-103              [-1, 37, 768]               0\n",
      "         Dropout-104              [-1, 37, 768]               0\n",
      "ResidualConnection-105              [-1, 37, 768]               0\n",
      "Transformer_Block-106              [-1, 37, 768]               0\n",
      "       LayerNorm-107              [-1, 37, 768]           1,536\n",
      "          Linear-108              [-1, 37, 768]         590,592\n",
      "          Linear-109              [-1, 37, 768]         590,592\n",
      "          Linear-110              [-1, 37, 768]         590,592\n",
      "          Linear-111              [-1, 37, 768]         590,592\n",
      "Multi_Head_Attention-112              [-1, 37, 768]               0\n",
      "         Dropout-113              [-1, 37, 768]               0\n",
      "ResidualConnection-114              [-1, 37, 768]               0\n",
      "       LayerNorm-115              [-1, 37, 768]           1,536\n",
      "          Linear-116             [-1, 37, 3072]       2,362,368\n",
      "            GELU-117             [-1, 37, 3072]               0\n",
      "         Dropout-118             [-1, 37, 3072]               0\n",
      "          Linear-119              [-1, 37, 768]       2,360,064\n",
      "     FeedForward-120              [-1, 37, 768]               0\n",
      "         Dropout-121              [-1, 37, 768]               0\n",
      "ResidualConnection-122              [-1, 37, 768]               0\n",
      "Transformer_Block-123              [-1, 37, 768]               0\n",
      "       LayerNorm-124              [-1, 37, 768]           1,536\n",
      "          Linear-125              [-1, 37, 768]         590,592\n",
      "          Linear-126              [-1, 37, 768]         590,592\n",
      "          Linear-127              [-1, 37, 768]         590,592\n",
      "          Linear-128              [-1, 37, 768]         590,592\n",
      "Multi_Head_Attention-129              [-1, 37, 768]               0\n",
      "         Dropout-130              [-1, 37, 768]               0\n",
      "ResidualConnection-131              [-1, 37, 768]               0\n",
      "       LayerNorm-132              [-1, 37, 768]           1,536\n",
      "          Linear-133             [-1, 37, 3072]       2,362,368\n",
      "            GELU-134             [-1, 37, 3072]               0\n",
      "         Dropout-135             [-1, 37, 3072]               0\n",
      "          Linear-136              [-1, 37, 768]       2,360,064\n",
      "     FeedForward-137              [-1, 37, 768]               0\n",
      "         Dropout-138              [-1, 37, 768]               0\n",
      "ResidualConnection-139              [-1, 37, 768]               0\n",
      "Transformer_Block-140              [-1, 37, 768]               0\n",
      "       LayerNorm-141              [-1, 37, 768]           1,536\n",
      "          Linear-142              [-1, 37, 768]         590,592\n",
      "          Linear-143              [-1, 37, 768]         590,592\n",
      "          Linear-144              [-1, 37, 768]         590,592\n",
      "          Linear-145              [-1, 37, 768]         590,592\n",
      "Multi_Head_Attention-146              [-1, 37, 768]               0\n",
      "         Dropout-147              [-1, 37, 768]               0\n",
      "ResidualConnection-148              [-1, 37, 768]               0\n",
      "       LayerNorm-149              [-1, 37, 768]           1,536\n",
      "          Linear-150             [-1, 37, 3072]       2,362,368\n",
      "            GELU-151             [-1, 37, 3072]               0\n",
      "         Dropout-152             [-1, 37, 3072]               0\n",
      "          Linear-153              [-1, 37, 768]       2,360,064\n",
      "     FeedForward-154              [-1, 37, 768]               0\n",
      "         Dropout-155              [-1, 37, 768]               0\n",
      "ResidualConnection-156              [-1, 37, 768]               0\n",
      "Transformer_Block-157              [-1, 37, 768]               0\n",
      "       LayerNorm-158              [-1, 37, 768]           1,536\n",
      "          Linear-159              [-1, 37, 768]         590,592\n",
      "          Linear-160              [-1, 37, 768]         590,592\n",
      "          Linear-161              [-1, 37, 768]         590,592\n",
      "          Linear-162              [-1, 37, 768]         590,592\n",
      "Multi_Head_Attention-163              [-1, 37, 768]               0\n",
      "         Dropout-164              [-1, 37, 768]               0\n",
      "ResidualConnection-165              [-1, 37, 768]               0\n",
      "       LayerNorm-166              [-1, 37, 768]           1,536\n",
      "          Linear-167             [-1, 37, 3072]       2,362,368\n",
      "            GELU-168             [-1, 37, 3072]               0\n",
      "         Dropout-169             [-1, 37, 3072]               0\n",
      "          Linear-170              [-1, 37, 768]       2,360,064\n",
      "     FeedForward-171              [-1, 37, 768]               0\n",
      "         Dropout-172              [-1, 37, 768]               0\n",
      "ResidualConnection-173              [-1, 37, 768]               0\n",
      "Transformer_Block-174              [-1, 37, 768]               0\n",
      "       LayerNorm-175              [-1, 37, 768]           1,536\n",
      "          Linear-176              [-1, 37, 768]         590,592\n",
      "          Linear-177              [-1, 37, 768]         590,592\n",
      "          Linear-178              [-1, 37, 768]         590,592\n",
      "          Linear-179              [-1, 37, 768]         590,592\n",
      "Multi_Head_Attention-180              [-1, 37, 768]               0\n",
      "         Dropout-181              [-1, 37, 768]               0\n",
      "ResidualConnection-182              [-1, 37, 768]               0\n",
      "       LayerNorm-183              [-1, 37, 768]           1,536\n",
      "          Linear-184             [-1, 37, 3072]       2,362,368\n",
      "            GELU-185             [-1, 37, 3072]               0\n",
      "         Dropout-186             [-1, 37, 3072]               0\n",
      "          Linear-187              [-1, 37, 768]       2,360,064\n",
      "     FeedForward-188              [-1, 37, 768]               0\n",
      "         Dropout-189              [-1, 37, 768]               0\n",
      "ResidualConnection-190              [-1, 37, 768]               0\n",
      "Transformer_Block-191              [-1, 37, 768]               0\n",
      "       LayerNorm-192              [-1, 37, 768]           1,536\n",
      "          Linear-193              [-1, 37, 768]         590,592\n",
      "          Linear-194              [-1, 37, 768]         590,592\n",
      "          Linear-195              [-1, 37, 768]         590,592\n",
      "          Linear-196              [-1, 37, 768]         590,592\n",
      "Multi_Head_Attention-197              [-1, 37, 768]               0\n",
      "         Dropout-198              [-1, 37, 768]               0\n",
      "ResidualConnection-199              [-1, 37, 768]               0\n",
      "       LayerNorm-200              [-1, 37, 768]           1,536\n",
      "          Linear-201             [-1, 37, 3072]       2,362,368\n",
      "            GELU-202             [-1, 37, 3072]               0\n",
      "         Dropout-203             [-1, 37, 3072]               0\n",
      "          Linear-204              [-1, 37, 768]       2,360,064\n",
      "     FeedForward-205              [-1, 37, 768]               0\n",
      "         Dropout-206              [-1, 37, 768]               0\n",
      "ResidualConnection-207              [-1, 37, 768]               0\n",
      "Transformer_Block-208              [-1, 37, 768]               0\n",
      "TransformerEncoder-209              [-1, 37, 768]               0\n",
      "       LayerNorm-210                  [-1, 768]           1,536\n",
      "          Linear-211                 [-1, 1000]         769,000\n",
      "        MLP_Head-212                 [-1, 1000]               0\n",
      "         Softmax-213                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 86,526,184\n",
      "Trainable params: 86,526,184\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 68.74\n",
      "Params size (MB): 330.07\n",
      "Estimated Total Size (MB): 398.91\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(ViT(img_size=ims.shape[1:]).to(device), (3, 96, 96), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 장에서는 구현된 ViT 를 사용하여 간단한 train 과 inference 를 다뤄보도록 합시다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
